import pandas as pd
import numpy as np
import torch
import os
import sys

class MovieLensProcessor:
    def __init__(self, data_path="data/raw/ml-1m/ratings.dat", seq_len=20, min_len=5):
        # è·å–å½“å‰è„šæœ¬è¿è¡Œçš„æ ¹ç›®å½•ï¼Œç¡®ä¿èƒ½æ‰¾åˆ° data æ–‡ä»¶å¤¹
        current_dir = os.getcwd()
        # å¦‚æœ data_path æ˜¯ç›¸å¯¹è·¯å¾„ï¼Œæ‹¼æ¥ä¸Šå½“å‰ç›®å½•
        if not os.path.isabs(data_path):
            self.data_path = os.path.join(current_dir, data_path)
        else:
            self.data_path = data_path
            
        self.seq_len = seq_len
        self.min_len = min_len
        self.user2id = {}
        self.item2id = {}
        self.n_items = 0
        
    def load_data(self):
        print(f"ğŸ”„ Loading MovieLens data from: {self.data_path}")
        
        if not os.path.exists(self.data_path):
            raise FileNotFoundError(f"Raw data not found at {self.data_path}")

        # MovieLens 1M format: UserID::MovieID::Rating::Timestamp
        df = pd.read_csv(self.data_path, sep='::', header=None, engine='python',
                         names=['uid', 'mid', 'rating', 'timestamp'])
        
        # 1. é‡æ–°ç¼–ç  ID (0 å·ç•™ç»™ padding)
        self.item2id = {mid: i+1 for i, mid in enumerate(df['mid'].unique())}
        self.n_items = len(self.item2id) + 1
        df['item_idx'] = df['mid'].map(self.item2id)
        
        # 2. æŒ‰ç”¨æˆ·åˆ†ç»„å¹¶æ’åº
        print("ğŸ”„ Grouping by user and sorting time...")
        data_group = df.sort_values(['uid', 'timestamp']).groupby('uid')
        
        sequences = []
        for uid, group in data_group:
            items = group['item_idx'].values.tolist()
            times = group['timestamp'].values.tolist()
            
            if len(items) < self.min_len:
                continue
                
            # åˆ‡åˆ†åºåˆ— (åªå–æœ€è¿‘çš„ä¸€æ®µ seq_len)
            seq_items = items[-self.seq_len:]
            seq_times = times[-self.seq_len:]
            
            # Padding (ä¸å¤Ÿé•¿çš„è¡¥ 0)
            pad_len = self.seq_len - len(seq_items)
            if pad_len > 0:
                seq_items = [0] * pad_len + seq_items
                seq_times = [seq_times[0]] * pad_len + seq_times
            
            # Time Normalization
            # å½’ä¸€åŒ–æ—¶é—´æˆ³ï¼Œé˜²æ­¢æ•°å€¼è¿‡å¤§å¯¼è‡´ ODE æ¢¯åº¦çˆ†ç‚¸
            seq_times = np.array(seq_times)
            t0 = seq_times[0]
            # ç¼©æ”¾åˆ° [0, 10] å·¦å³çš„åŒºé—´
            norm_times = (seq_times - t0) / 3600.0 / 24.0 / 10.0 
            norm_times = np.maximum.accumulate(norm_times)
            
            sequences.append((seq_items, norm_times.tolist()))
            
        return sequences

    def save_processed(self, save_path="data/processed.pt"):
        try:
            seqs = self.load_data()
            print(f"âœ… Processed {len(seqs)} sequences. Saving to {save_path}...")
            os.makedirs(os.path.dirname(save_path), exist_ok=True)
            torch.save({
                "sequences": seqs,
                "n_items": self.n_items,
                "item2id": self.item2id
            }, save_path)
            print("ğŸ‰ Data processing complete!")
        except Exception as e:
            print(f"âŒ Error during processing: {e}")


if __name__ == "__main__":
    # è‡ªåŠ¨æ£€æŸ¥å¹¶å°è¯•ä¸‹è½½
    raw_path = "data/raw/ml-1m/ratings.dat"
    zip_path = "data/raw/ml-1m.zip"
    
    if not os.path.exists(raw_path):
        print(f"âš ï¸ Data not found at {raw_path}")
        print("ğŸ”„ Attempting automatic download...")
        try:
            os.makedirs("data/raw", exist_ok=True)
            # ä½¿ç”¨ curl ä¸‹è½½
            if os.system(f"curl -o {zip_path} https://files.grouplens.org/datasets/movielens/ml-1m.zip") == 0:
                print("âœ… Download success. Unzipping...")
                os.system(f"unzip -o {zip_path} -d data/raw")
            else:
                raise Exception("Curl command failed.")
        except Exception as e:
            print(f"âŒ Automatic download failed: {e}")
            print("ğŸ’¡ Please manually download ml-1m.zip from grouplens.org and place it in 'data/raw/'.")
            sys.exit(1)

    print("ğŸš€ Starting Preprocessor...")
    processor = MovieLensProcessor(data_path=raw_path)
    processor.save_processed()