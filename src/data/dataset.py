import torch
from torch.utils.data import Dataset
import numpy as np
import os

class UserBehaviorDataset(Dataset):
    def __init__(self, mode='train', config=None):
        self.mode = mode
        
        # 1. è·¯å¾„å¤„ç†
        # å‡è®¾ processed.pt åœ¨ data/ ç›®å½•ä¸‹
        data_path = "data/processed.pt"
        if config and 'data' in config and 'data_path' in config['data']:
            data_path = config['data']['data_path']
            
        if not os.path.exists(data_path):
            raise FileNotFoundError(f"Data file not found at {data_path}. Please run training first or check path.")

        # 2. åŠ è½½æ•°æ®
        # weights_only=False æ˜¯ä¸ºäº†å…¼å®¹æ—§ç‰ˆ PyTorch ä¿å­˜çš„å­—å…¸æ ¼å¼
        print(f"ğŸ“¦ Loading dataset from {data_path}...")
        payload = torch.load(data_path, map_location='cpu', weights_only=False)
        
        # å…¼å®¹ä¸¤ç§ä¿å­˜æ ¼å¼ï¼šå¯èƒ½æ˜¯ dictï¼Œä¹Ÿå¯èƒ½ç›´æ¥æ˜¯ list
        if isinstance(payload, dict):
            self.sequences = payload.get('sequences', [])
            self.n_items = payload.get('n_items', 3707)
        else:
            self.sequences = payload
            self.n_items = 3707 # Fallback
            
        # 3. åˆ’åˆ† Train/Test
        total_len = len(self.sequences)
        train_size = int(0.8 * total_len)
        
        if mode == 'train':
            self.data = self.sequences[:train_size]
        else:
            self.data = self.sequences[train_size:]
            
        print(f"âœ… Loaded {len(self.data)} sequences for {mode}.")

    def __len__(self):
        return len(self.data)
    
    def __getitem__(self, idx):
        # data[idx] ç»“æ„: (items_list, times_list, label_item)
        # æˆ–è€… (items, times) å–å†³äºé¢„å¤„ç†é€»è¾‘ã€‚
        # è¿™é‡Œå‡è®¾æ˜¯æ ‡å‡†çš„ seq æ ¼å¼
        
        seq_data = self.data[idx]
        items = seq_data[0]
        times = seq_data[1]
        
        # æˆªæ–­ä¸è½¬æ¢
        # Input: 0 ~ T-1
        # Target: 1 ~ T (Next Item Prediction) -> è¿™é‡Œä¸ºäº†ç®€åŒ– ODE è®­ç»ƒï¼Œé€šå¸¸ç”¨ Auto-regressive æ–¹å¼
        
        # è½¬æ¢ä¸º Tensor
        x = torch.tensor(items[:-1], dtype=torch.long)
        y = torch.tensor(items[1:], dtype=torch.long) # ç®€å•çš„ Next Item ç›‘ç£
        
        # æ—¶é—´æˆ³å¤„ç†
        t_raw = np.array(times[:-1], dtype=np.float32)
        
        # å¼ºåˆ¶å•è°ƒé€’å¢ (Monotonicity Check)
        # é˜²æ­¢æ•°æ®å™ªéŸ³å¯¼è‡´ dt < 0ï¼Œè¿™ä¼šè®© Neural ODE æ±‚è§£å™¨å´©æºƒ
        t_safe = np.maximum.accumulate(t_raw)
        
        # é˜²æ­¢å®Œå…¨ç›¸åŒçš„æ—¶é—´æˆ³ (dt=0)ï¼ŒåŠ ä¸Šæå°æ‰°åŠ¨
        # æ¯”å¦‚: [0.1, 0.1] -> [0.1, 0.10001]
        epsilon = 1e-5
        t_safe = t_safe + np.arange(len(t_safe)) * epsilon
        
        t = torch.tensor(t_safe, dtype=torch.float32)
        
        # å¦‚æœéœ€è¦ï¼Œè¿™é‡Œå¯ä»¥åªè¿”å›æœ€åä¸€ä¸ª target ç”¨äºè¯„ä¼°
        target_item = torch.tensor(items[-1], dtype=torch.long)

        return {
            "x": x,           # [Seq_len]
            "t": t,           # [Seq_len] (Strictly Increasing)
            "y": target_item  # Scalar
        }