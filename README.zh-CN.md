# DeepM3: 基于神经ODE的连续时间动态会话推荐模型

DeepM3 解决了传统离散时间序列模型（如 RNN、Transformer）在处理真实世界具有不规则时间间隔的交互时的固有限制。通过将用户意图演化构建为**连续时间动力系统 (Continuous-Time Dynamical System)**，DeepM3 使得意图能够在未被观测到的时间区间内，于潜在空间中平滑演化。

此外，我们将充满变数（商品上新、用户兴趣漂移）的推荐环境定义为一个**随机动力系统 (Random Dynamical System, RDS)**。在高环境噪声下（这可以通过*随机拓扑熵*来衡量），传统的离散模型由于对时间的极度敏感或直接无视，极易发生崩溃。而我们基于 ODE 的架构，借助于李普希茨连续性（Lipschitz continuity），展现出了极其卓越的鲁棒性，从数学层面上削弱了序列随机破坏带来的致命影响。

---

## 🚀 核心实验结论 (支撑 KBS 投稿)

为了支撑严谨的理论框架，本次实验将极度稠密、结构化的大数据与极度稀疏、高不规则的长尾数据进行了充分对标：

### 1. 对抗高不规则性 (High Irregularity)
当用户交互时间变得愈发混沌（如变异系数 CV 极大）时，DeepM3 展现了其作为连续演化系统的绝对统治力。
* **ML-1M (高质量稠密):** 在最不规律的交互序列中，连续时间积分为模型带来了 **+2.27%** 显著指标回涨。
* **Amazon Books (极度稀疏且长尾):** 在人为注入时间噪音干扰演化时，传统方法崩溃，而 DeepM3 的表现只极其微小地掉了 **0.36% (NDCG)**，这种工业级环境的“抗震防噪机制”印证了我们的 RDS 体系。

### 2. 效率与精度的权衡 
我们提供适用于不同工业要求的算子降级：
* **DeepM3 (RK4)**: 提供理论上的最高精度 (ML-1M 上 NDCG@10 触及 0.4078)。
* **DeepM3 (Euler)**: 定制化的低延迟工业级版本（以一半甚至三分之一的延迟，换取超过强基线的统计算法增幅）。
* 相对于多达 **260 万**参数的 SASRec 等巨无霸模型，DeepM3 参数只有可怜的约 **80 万**，依旧具有非常强势的性能。

---

## ⚙️ 一键复现流程

为了满足双盲审稿人对于 Reproducibility（可重复性）的苛刻校验，我们提供了一键跑通所有实验的基础脚本：

### 1. 环境依赖配置
```bash
conda create -n DeepM3 python=3.10
conda activate DeepM3
pip install torch pandas numpy scipy pyyaml tqdm
```

### 2. 运行完整的 ML-1M 实验 (常规稠密场景)
自动执行包含了最佳参数搜网格索、深层训练以及八项分析实验（显著性、鲁棒性、有效性、时序混乱抗性等）：
```bash
DEVICE=auto bash scripts/experiments/run_phase2.sh
# 最后的各项 CSV 报告将在 `results/ml1m/` 中生成。
```

### 3. 运行完整的 Amazon 实验 (极度稀疏/高噪场景)
自动拉取 Amazon 5-core 图书推荐，执行流转化压缩与对应的所有极端实验环境：
```bash
DEVICE=auto bash scripts/experiments/run_amazon.sh
# 最后的各项 CSV 报告将在 `results/amazon/` 中生成。
```

---

## 🧠 理论亮点
1. **基于时间的 ODE 积分:** 未被观察到的时间跨度决定了 ODE 积分演化步长 $(dt)$，调整隐向量状态且无需进行虚假零点 Padding 对齐。
2. **RDS 鲁棒抗性:** 在不进行特殊强化学习训练的前提下，原生极高标准抵抗随机时间抖动和 Dropout。
3. **可插拔推演求解器:** 支持从适用于 Edge 前端的 `Euler` 求解到适用于高算力中心的 `RK4` 机制的无缝拉满。

## Citation
*(目前作为 KBS 的双盲实验资源保留为匿名仓库)*
