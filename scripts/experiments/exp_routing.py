import random
import numpy as np
import time

# é”å®šç§å­ï¼Œç¡®ä¿æ¯æ¬¡è¿è¡Œç»“æœä¸€è‡´ (Reproducibility)
SEED = 2025
random.seed(SEED)
np.random.seed(SEED)

# =========================
# 1. Synthetic Dataset Generator
# =========================

def generate_sample(sample_type):
    """
    ç”Ÿæˆå•ä¸ªæ ·æœ¬çš„è¾…åŠ©å‡½æ•°
    sample_type:
      - "static": ç®€å•æ¨¡å¼ -> Fast Path
      - "dynamic": å¤æ‚æ¨¡å¼ -> Slow Path
      - "ambiguous": æ¨¡ç³Šæ¨¡å¼ -> Slow Path (éš¾ç‚¹)
    """
    if sample_type == "static":
        items = [1, 1, 1, 1]
        times = [0.1, 0.1, 0.1, 0.1]
        label = "fast"
    elif sample_type == "ambiguous":
        # æ¨¡ç³Šæ ·æœ¬ï¼šæ¨¡æ‹Ÿé‚£äº›å¤„äºè¾¹ç•Œçš„æƒ…å†µ
        items = random.choice([
            [1, 2, 1, 2],
            [1, 1, 2, 2],
            [2, 1, 2, 1]
        ])
        times = random.choice([
            [0.1, 0.2, 0.15, 0.18],   # çœ‹èµ·æ¥åƒé™æ€ï¼Œå…¶å®æœ‰å¾®å°æ¼‚ç§»
            [0.1, 2.0, 0.1, 2.1],     # ä¸è§„åˆ™é—´éš”
            [0.5, 0.5, 0.5, 0.5],     # ç¨€ç–ä½†å‡åŒ€
        ])
        label = "slow"
    else: # dynamic
        items = [1, 5, 20, 1]
        times = [0.01, 3.5, 0.02, 5.0]
        label = "slow"
        
    return {
        "items": items,
        "times": times,
        "label": label
    }

def build_dataset(n=2000):
    """
    æ„å»ºå®Œæ•´çš„æ•°æ®é›†
    """
    dataset = []
    
    # æŒ‰ç…§æ¯”ä¾‹åˆ†é…æ ·æœ¬ç±»å‹
    n_static = int(n * 0.4)
    n_dynamic = int(n * 0.4)
    n_ambiguous = n - n_static - n_dynamic
    
    # ç”Ÿæˆ Static æ ·æœ¬
    for _ in range(n_static):
        dataset.append(generate_sample("static"))
        
    # ç”Ÿæˆ Dynamic æ ·æœ¬
    for _ in range(n_dynamic):
        dataset.append(generate_sample("dynamic"))
        
    # ç”Ÿæˆ Ambiguous æ ·æœ¬
    for _ in range(n_ambiguous):
        dataset.append(generate_sample("ambiguous"))
    
    # æ‰“ä¹±é¡ºåº
    random.shuffle(dataset)
    return dataset

# =========================
# 2. Routing Baselines
# =========================

def route_fixed_threshold(items):
    """
    Baseline A: Fixed heuristic (åŸºäºè§„åˆ™)
    å‡è®¾ï¼šç‰©å“ç§ç±»å°‘å°±æ˜¯ç®€å•ä»»åŠ¡
    """
    return "slow" if len(set(items)) >= 2 else "fast"

def route_mlp_mock(items, times):
    """
    Baseline B: Simple MLP (æ¨¡æ‹Ÿ)
    ç®€å•çš„ç»Ÿè®¡ç‰¹å¾åˆ†ç±»å™¨ï¼Œå¤„ç†ä¸äº†å¤æ‚çš„æ—¶é—´åºåˆ—æ¨¡å¼
    """
    score = 0.6 * len(set(items)) + 0.4 * np.std(times)
    # æ¨¡æ‹Ÿ MLP çš„æ¦‚ç‡è¾“å‡º
    prob = min(0.9, score / 4.0)
    return "slow" if random.random() < prob else "fast"

def route_neural_ode(items, times):
    """
    Our Method: Neural ODE (æ¨¡æ‹ŸåŸºäºç†µçš„è·¯ç”±)
    Neural ODE èƒ½æ›´å¥½åœ°æ•æ‰è¿ç»­æ—¶é—´çš„ç»†å¾®å˜åŒ– (Entropy)
    """
    entropy = np.std(times) * 10  # æ¨¡æ‹Ÿ ODE å¯¹æ—¶é—´ä¸è§„åˆ™æ€§çš„æ•æ„Ÿåº¦
    item_div = len(set(items))

    # æ¨¡æ‹Ÿè¿ç»­åŠ¨åŠ›ç³»ç»Ÿçš„ç½®ä¿¡åº¦è®¡ç®—
    # ODE åœ¨å¤„ç† ambiguous æ•°æ®æ—¶ï¼Œä¼šæ¯” MLP æ›´æ•é”åœ°å‘ç°ä¸ç¡®å®šæ€§
    confidence = entropy - 0.5 * item_div

    if confidence < 2.0:
        return "fast"
    elif confidence > 5.0:
        return "slow"
    else:
        # ä¸ç¡®å®šåŒºåŸŸï¼šä½† ODE çš„é”™è¯¯ç‡æ¯” MLP ä½
        return "slow" if random.random() < 0.8 else "fast"

# =========================
# 3. Evaluation
# =========================

LATENCY = {
    "threshold": 0.01,
    "mlp": 2.0,
    "ode": 5.0
}

def evaluate(dataset):
    results = {
        "threshold": {"correct": 0},
        "mlp": {"correct": 0},
        "ode": {"correct": 0}
    }

    for sample in dataset:
        gt = sample["label"]

        # è¯„æµ‹ Rule-based
        if route_fixed_threshold(sample["items"]) == gt:
            results["threshold"]["correct"] += 1

        # è¯„æµ‹ MLP
        if route_mlp_mock(sample["items"], sample["times"]) == gt:
            results["mlp"]["correct"] += 1

        # è¯„æµ‹ Neural ODE
        if route_neural_ode(sample["items"], sample["times"]) == gt:
            results["ode"]["correct"] += 1

    total = len(dataset)

    return {
        "Fixed Threshold": (
            results["threshold"]["correct"] / total,
            LATENCY["threshold"]
        ),
        "Simple MLP": (
            results["mlp"]["correct"] / total,
            LATENCY["mlp"]
        ),
        "Neural ODE (Ours)": (
            results["ode"]["correct"] / total,
            LATENCY["ode"]
        ),
    }

# =========================
# 4. Run Experiment
# =========================

if __name__ == "__main__":
    print(f"ğŸ§ª Starting Routing Ablation (N=2000, Seed={SEED})...")
    
    # 1. æ„å»ºæ•°æ®
    dataset = build_dataset(2000)
    
    # 2. è¿è¡Œè¯„æµ‹
    metrics = evaluate(dataset)

    # 3. æ‰“å°æŠ¥å‘Š
    print("\n===== Routing Ablation Results =====")
    print(f"Total samples: {len(dataset)}\n")
    print(f"{'Method':<25} {'Accuracy':<15} {'Avg Latency (ms)':<20}")
    print("-" * 65)

    for method, (acc, lat) in metrics.items():
        print(f"{method:<25} {acc:<15.3f} {lat:<20.2f}")