import argparse
import yaml
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import sys
import os
import time

# Path Hack
sys.path.append(os.getcwd())

from src.data.dataset import UserBehaviorDataset 
from src.dynamics.modeling import DeepM3Model
from src.utils.seeder import set_seed
from src.utils.env_check import print_env_fingerprint

def train(args):
    # 1. ç¯å¢ƒå‡†å¤‡
    print_env_fingerprint()
    set_seed(args.seed)
    
    device = torch.device("cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu")
    print(f"ğŸš€ Training on Device: {device}")
    print(f"âš™ï¸  Solver Strategy: {args.solver.upper()}") # æ‰“å°å½“å‰ç­–ç•¥

    # 2. åŠ è½½é…ç½®
    with open(args.config, 'r') as f:
        config = yaml.safe_load(f)

    # 3. æ•°æ®å‡†å¤‡
    try:
        train_dataset = UserBehaviorDataset(mode='train', config=config)
        # ä¸ºäº† Ablation è·‘å¾—å¿«ä¸€ç‚¹ï¼Œå¦‚æœæ˜¯æ¼”ç¤ºï¼Œå¯ä»¥å‡å°‘ epoch æˆ–æ•°æ®é‡
        n_items = train_dataset.n_items
    except Exception as e:
        print(f"âŒ Data Load Error: {e}")
        return

    train_loader = DataLoader(train_dataset, batch_size=config['train']['batch_size'], shuffle=True)

    # 4. æ¨¡å‹åˆå§‹åŒ–
    # [Mod] è¿™é‡Œçš„å…³é”®ï¼šæŠŠ args.solver ä¼ ç»™æ¨¡å‹
    model = DeepM3Model(config, n_items=n_items, solver=args.solver).to(device)
    
    optimizer = optim.Adam(model.parameters(), lr=float(config['train']['learning_rate']))
    criterion = nn.CrossEntropyLoss()

    # 5. è®­ç»ƒå¾ªç¯
    print(f"ğŸ”¥ Start Training for {args.epochs} Epochs...")
    best_loss = float('inf')
    
    for epoch in range(args.epochs):
        model.train()
        total_loss = 0
        start_time = time.time()
        
        for batch in train_loader:
            optimizer.zero_grad()
            x = batch['x'].to(device)
            t = batch['t'].to(device)
            y = batch['y'].to(device)
            
            # Forward (å†…éƒ¨ä¼šæ ¹æ® solver='none'/'rk4' èµ°ä¸åŒè·¯å¾„)
            logits = model(x, t)
            
            loss = criterion(logits, y)
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
            optimizer.step()
            total_loss += loss.item()
            
        avg_loss = total_loss / len(train_loader)
        epoch_time = time.time() - start_time
        
        print(f"   Epoch {epoch+1}/{args.epochs} | Loss: {avg_loss:.4f} | Time: {epoch_time:.1f}s")
        
        # 6. ä¿å­˜é€»è¾‘
        # [Mod] ä½¿ç”¨ args.save_name åŠ¨æ€å†³å®šä¿å­˜æ–‡ä»¶å
        if avg_loss < best_loss:
            best_loss = avg_loss
            os.makedirs("checkpoints", exist_ok=True)
            save_path = f"checkpoints/{args.save_name}"
            torch.save(model.state_dict(), save_path)
            
    print(f"âœ… Training Complete. Best Loss: {best_loss:.4f}")
    print(f"ğŸ’¾ Model saved to: {save_path}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('--config', type=str, default='configs/config.yaml')
    parser.add_argument('--epochs', type=int, default=5)
    parser.add_argument('--seed', type=int, default=42)
    
    # [Mod] æ–°å¢æ¶ˆèå®éªŒå‚æ•°
    parser.add_argument('--solver', type=str, default='rk4', choices=['none', 'euler', 'rk4'], help="ODE solver method")
    parser.add_argument('--save_name', type=str, default='model_ode_rk4.pth', help="Checkpoint filename")
    
    args = parser.parse_args()
    train(args)